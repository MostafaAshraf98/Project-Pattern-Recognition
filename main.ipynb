{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from dataloader.dataloader import DataLoader\n",
    "from preprocessing.clustering_segmentation import ClusteringSegmentation\n",
    "from preprocessing.edge_detection import EdgeDetection\n",
    "from preprocessing.image_restoration import ImageRestorer\n",
    "from preprocessing.preproccessing import ImagePreprocessor\n",
    "from preprocessing.region_segmentation import RegionBasedSegmentation\n",
    "from preprocessing.threshold_segmentation import ThresholdSegmentation\n",
    "from feature_extraction.feature_extraction import FeatureExtractor\n",
    "from feature_selection.feature_selection import FeatureSelector\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
    "from preprocessing.image_aligner import ImageAligner\n",
    "import pickle\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Path('./data'))\n",
    "\n",
    "# Load Data from files\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data(data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illumination Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illumination_processing = IlluminationPreprocessing()\n",
    "\n",
    "illuminated_list = illumination_processing.process_images_loops(x_train)\n",
    "illuminated_train = [t[0] for t in illuminated_list]\n",
    "illuminated_train_mask = [t[1] for t in illuminated_list]\n",
    "\n",
    "illuminated_list_val = illumination_processing.process_images_loops(x_val)\n",
    "illuminated_val = [t[0] for t in illuminated_list_val]\n",
    "illuminated_val_mask = [t[1] for t in illuminated_list_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illuminated_train = np.array(illuminated_train)\n",
    "illuminated_train_mask = np.array(illuminated_train_mask)\n",
    "illuminated_val = np.array(illuminated_val)\n",
    "illuminated_val_mask = np.array(illuminated_val_mask)\n",
    "\n",
    "print(f\"illuminated_train shape: {illuminated_train.shape}\")\n",
    "print(f\"illuminated_train_mask shape: {illuminated_train_mask.shape}\")\n",
    "print(f\"illuminated_val shape: {illuminated_val.shape}\")\n",
    "print(f\"illuminated_val_mask shape: {illuminated_val_mask.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_aligner = ImageAligner()\n",
    "\n",
    "aligned_train = image_aligner.align_image(illuminated_train)\n",
    "aligned_val = image_aligner.align_image(illuminated_val)\n",
    "\n",
    "print(f\"aligned_train shape: {aligned_train.shape}\")\n",
    "print(f\"aligned_val shape: {aligned_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(aligned_train))\n",
    "print(index)\n",
    "plt.imshow(aligned_train[index])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection = EdgeDetection(method=\"canny\")\n",
    "edge_detected_train = edge_detection.process(illuminated_train)\n",
    "edge_detected_val = edge_detection.process(illuminated_val)\n",
    "\n",
    "print(f\"edge_detected_train shape: {edge_detected_train.shape}\")\n",
    "print(f\"edge_detected_val shape: {edge_detected_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction And Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "feature_selector = FeatureSelector()\n",
    "\n",
    "pca_features_train = np.zeros((x_train.shape[0],0))\n",
    "pca_features_val = np.zeros((x_val.shape[0],0))\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hog Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features_train = feature_extractor.extract_hog_features(aligned_train)\n",
    "hog_features_val = feature_extractor.extract_hog_features(aligned_val)\n",
    "\n",
    "pca_hog_features_train = feature_selector.extract_pca_features(hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hog_features_val = feature_selector.extract_pca_features(hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hog_features_val.shape}\")\n",
    "\n",
    "print(f\"hog pca features train shape: {pca_hog_features_train.shape}\")\n",
    "print(f\"hog pca features val shape: {pca_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_features_train = feature_extractor.extract_lbp_features(illuminated_train)\n",
    "lbp_features_val = feature_extractor.extract_lbp_features(illuminated_val)\n",
    "\n",
    "pca_lbp_features_train = feature_selector.extract_pca_features(lbp_features_train,load=False, num_pca_components=0.95)\n",
    "pca_lbp_features_val = feature_selector.extract_pca_features(lbp_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_lbp_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_lbp_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {lbp_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"lbp pca features train shape: {pca_lbp_features_train.shape}\")\n",
    "print(f\"lbp pca features val shape: {pca_lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images_train = np.zeros((x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "gray_images_val = np.zeros((x_val.shape[0], x_val.shape[1], x_val.shape[2]))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    gray_images_train[i] = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "for i in range(x_val.shape[0]):\n",
    "    gray_images_val[i] = cv2.cvtColor(x_val[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift_features_train = feature_extractor.extract_sift_features(illuminated_train)\n",
    "sift_features_val = feature_extractor.extract_sift_features(illuminated_val)\n",
    "\n",
    "\n",
    "pca_sift_features_train = feature_selector.extract_pca_features(sift_features_train,load=False, num_pca_components=0.95)\n",
    "pca_sift_features_val = feature_selector.extract_pca_features(sift_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_sift_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_sift_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {sift_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {sift_features_val.shape}\")\n",
    "\n",
    "print(f\"sift pca features train shape: {pca_sift_features_train.shape}\")\n",
    "print(f\"sift pca features val shape: {pca_sift_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAISY Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daisy_features_train = feature_extractor.extract_daisy_features(aligned_train)\n",
    "daisy_features_val = feature_extractor.extract_daisy_features(aligned_val)\n",
    "\n",
    "pca_daisy_features_train = feature_selector.extract_pca_features(daisy_features_train,load=False, num_pca_components=0.95)\n",
    "pca_daisy_features_val = feature_selector.extract_pca_features(daisy_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {daisy_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca_daisy_features_train, open(\"pca_daisy_features_train.pkl\", \"wb\"))\n",
    "pickle.dump(pca_daisy_features_val, open(\"pca_daisy_features_val.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_daisy_features_train = pickle.load(open(\"pca_daisy_features_train.pkl\", \"rb\"))\n",
    "pca_daisy_features_val = pickle.load(open(\"pca_daisy_features_val.pkl\", \"rb\"))\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Descriptor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_features_train = feature_extractor.extract_fourier_descriptor_features(illuminated_train)\n",
    "fd_features_val = feature_extractor.extract_fourier_descriptor_features(illuminated_val)\n",
    "\n",
    "pca_fd_features_train = feature_selector.extract_pca_features(fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_fd_features_val = feature_selector.extract_pca_features(fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_fd_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {fd_features_val.shape}\")\n",
    "\n",
    "print(f\"fd pca features train shape: {pca_fd_features_train.shape}\")\n",
    "print(f\"fd pca features val shape: {pca_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_features_train = feature_extractor.extract_orb_features(illuminated_train)\n",
    "orb_features_val = feature_extractor.extract_orb_features(illuminated_val)\n",
    "\n",
    "pca_orb_features_train = feature_selector.extract_pca_features(orb_features_train,load=False, num_pca_components=0.95)\n",
    "pca_orb_features_val = feature_selector.extract_pca_features(orb_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_orb_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_orb_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {orb_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {orb_features_val.shape}\")\n",
    "\n",
    "print(f\"orb pca features train shape: {pca_orb_features_train.shape}\")\n",
    "print(f\"orb pca features val shape: {pca_orb_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RI HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_hog_features_train = feature_extractor.RI_HOG(illuminated_train_mask)\n",
    "ri_hog_features_val = feature_extractor.RI_HOG(illuminated_val_mask)\n",
    "\n",
    "pca_ri_hog_features_train = feature_selector.extract_pca_features(ri_hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_ri_hog_features_val = feature_selector.extract_pca_features(ri_hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_ri_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_ri_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {ri_hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"ri_hog pca features train shape: {pca_ri_hog_features_train.shape}\")\n",
    "print(f\"ri_hog pca features val shape: {pca_ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hu moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moment_features_train = feature_extractor.extract_hu_moments_features(illuminated_train_mask)\n",
    "hu_moment_features_val = feature_extractor.extract_hu_moments_features(illuminated_val_mask)\n",
    "\n",
    "pca_hu_moment_features_train = feature_selector.extract_pca_features(hu_moment_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hu_moment_features_val = feature_selector.extract_pca_features(hu_moment_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hu_moment_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hu_moment_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hu_moment_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"hu_moment pca features train shape: {pca_hu_moment_features_train.shape}\")\n",
    "print(f\"hu_moment pca features val shape: {pca_hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convex_hull_features_train, max_length_convex_hull = feature_extractor.extract_convex_hull_features(aligned_train)\n",
    "convex_hull_features_val,_ = feature_extractor.extract_convex_hull_features(aligned_val, max_length_convex_hull)\n",
    "\n",
    "print(f\"extracted_features shape: {convex_hull_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {convex_hull_features_val.shape}\")\n",
    "\n",
    "pca_convex_hull_features_train = feature_selector.extract_pca_features(convex_hull_features_train,load=False, num_pca_components=0.95)\n",
    "pca_convex_hull_features_val = feature_selector.extract_pca_features(convex_hull_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_convex_hull_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_convex_hull_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"convex_hull pca features train shape: {pca_convex_hull_features_train.shape}\")\n",
    "print(f\"convex_hull pca features val shape: {pca_convex_hull_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliiptical fourier descriptors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptical_fd_features_train = feature_extractor.elliptical_fourier_descriptors(aligned_train)\n",
    "elliptical_fd_features_val = feature_extractor.elliptical_fourier_descriptors(aligned_val)\n",
    "\n",
    "print(f\"extracted_features shape: {elliptical_fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {elliptical_fd_features_val.shape}\")\n",
    "\n",
    "pca_elliptic_fd_features_train = feature_selector.extract_pca_features(elliptical_fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_elliptic_fd_features_val = feature_selector.extract_pca_features(elliptical_fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_elliptic_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_elliptic_fd_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"elliptic_fd pca features train shape: {pca_elliptic_fd_features_train.shape}\")\n",
    "print(f\"elliptic_fd pca features val shape: {pca_elliptic_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the PCA extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)\n",
    "\n",
    "# save these 2 to files\n",
    "np.save(\"extracted_features_train_mean.npy\", extracted_features_train_mean)\n",
    "np.save(\"extracted_features_train_std.npy\", extracted_features_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_train = (pca_features_train - extracted_features_train_mean) /extracted_features_train_std\n",
    "pca_features_val = (pca_features_val - extracted_features_train_mean) /extracted_features_train_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: SVM Train\n",
      "Accuracy: 81.49%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: SVM VALIDATION\n",
      "Accuracy: 100.0%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_selection = ModelSelection(pca_features_train, y_train, pca_features_val, y_val)\n",
    "\n",
    "svm, pred_train, pred_val = model_selection.SVM()\n",
    "performance_analysis = PerformanceAnalysis('SVM Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('SVM VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "performance_analysis = PerformanceAnalysis('KNN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('KNN VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "ensemble, pred_train, pred_val = model_selection.Ensemble()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "adaboost, pred_train, pred_val = model_selection.AdaBoost()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 38\n",
      "output_dim: 6\n",
      "x_train: (1453, 38)\n",
      "y_train: (1453,)\n",
      "y_onehot: (1453, 6)\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 1s 7ms/step - loss: 1.7713 - accuracy: 0.5857 - val_loss: 1.2739 - val_accuracy: 0.7337\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1013 - accuracy: 0.7825 - val_loss: 1.1044 - val_accuracy: 0.7391\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8858 - accuracy: 0.8252 - val_loss: 0.9309 - val_accuracy: 0.7745\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.8658 - val_loss: 0.8622 - val_accuracy: 0.7690\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.8747 - val_loss: 0.7919 - val_accuracy: 0.7962\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.9167 - val_loss: 0.7977 - val_accuracy: 0.7799\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.9305 - val_loss: 0.7838 - val_accuracy: 0.7880\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.9566 - val_loss: 0.7289 - val_accuracy: 0.8098\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.9677 - val_loss: 0.7400 - val_accuracy: 0.8016\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.9711 - val_loss: 0.7477 - val_accuracy: 0.8043\n",
      "46/46 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Test accuracy: 0.804347813129425\n",
      "Test loss: 0.7477312684059143\n",
      "========================================\n",
      "Model: ANN Train\n",
      "Accuracy: 98.76%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: ANN Val\n",
      "Accuracy: 80.43%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ann, pred_train, pred_val = model_selection.ANN(input_dim=pca_features_train.shape[1], \n",
    "                                                output_dim=6)\n",
    "performance_analysis = PerformanceAnalysis('ANN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('ANN Val', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------TEST SET---------------------------------#\n",
    "data_loader = DataLoader(Path('./test'))\n",
    "illumination_processing = IlluminationPreprocessing()\n",
    "feature_extractor = FeatureExtractor()\n",
    "feature_selector = FeatureSelector()\n",
    "image_aligner = ImageAligner()\n",
    "\n",
    "\n",
    "\n",
    "# model = pickle.load(open(\"ann.h5\", \"rb\"))\n",
    "model = load_model(\"ann.h5\")\n",
    "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
    "extracted_features_train_mean = np.load(\"extracted_features_train_mean.npy\")\n",
    "extracted_features_train_std = np.load(\"extracted_features_train_std.npy\")\n",
    "\n",
    "\n",
    "path = Path('./test')\n",
    "\n",
    "# create a file named results.txt\n",
    "results_file = open(\"results.txt\", \"w\")\n",
    "\n",
    "# create a file named time.txt\n",
    "time_file = open(\"time.txt\", \"w\")\n",
    "\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "# Sort the list of files in increasing order\n",
    "files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "# Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
    "for i, filename in enumerate(files):\n",
    "    img = cv2.imread(os.path.join(path, filename))\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Get current time\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Resize the image\n",
    "    img = data_loader.custom_resize_img(img)\n",
    "    \n",
    "    # Illumination Preprocessing\n",
    "    illuminated_test, _ = illumination_processing.process_image(img)\n",
    "\n",
    "    # Image Alignment\n",
    "    aligned_test = image_aligner.align_image([illuminated_test])[0]\n",
    "\n",
    "    # Feature extraction and selection\n",
    "    daisy_features_test = feature_extractor.extract_daisy_features([aligned_test])[0]\n",
    "\n",
    "    pca_daisy_features_test = feature_selector.test_pca(daisy_features_test,pca)\n",
    "    \n",
    "    pca_daisy_features_test = (pca_daisy_features_test - extracted_features_train_mean) /extracted_features_train_std\n",
    "\n",
    "    # Model loading and prediction\n",
    "    model_prediction = model.predict(pca_daisy_features_test)\n",
    "\n",
    "    # Only in case of ANN\n",
    "    model_prediction = model_prediction.argmax(axis=1)\n",
    "    \n",
    "    # stop timer\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    total_time_seconds = round(end - start, 3)\n",
    "\n",
    "    # print(type(model_prediction[0]))\n",
    "    # print(model_prediction[0])\n",
    "\n",
    "    # write the prediction in results file\n",
    "    results_file.write(f\"{int(model_prediction[0])}\\n\")\n",
    "    \n",
    "    # write the time in times file\n",
    "    time_file.write(f\"{total_time_seconds}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
