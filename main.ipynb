{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from dataloader.dataloader import DataLoader\n",
    "from preprocessing.clustering_segmentation import ClusteringSegmentation\n",
    "from preprocessing.edge_detection import EdgeDetection\n",
    "from preprocessing.image_restoration import ImageRestorer\n",
    "from preprocessing.preproccessing import ImagePreprocessor\n",
    "from preprocessing.region_segmentation import RegionBasedSegmentation\n",
    "from preprocessing.threshold_segmentation import ThresholdSegmentation\n",
    "from feature_extraction.feature_extraction import FeatureExtractor\n",
    "from feature_selection.feature_selection import FeatureSelector\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
    "from preprocessing.image_aligner import ImageAligner\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Path('./data'))\n",
    "\n",
    "# Load Data from files\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data(data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1445, 320, 320, 3)\n",
      "y_train shape: (1445, 1)\n",
      "x_test shape: (188, 320, 320, 3)\n",
      "y_test shape: (188,)\n",
      "x_val shape: (188, 320, 320, 3)\n",
      "y_val shape: (188,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_zeros = x_train[y_train.flatten() == 0]\n",
    "x_train_ones = x_train[y_train.flatten() == 1]\n",
    "x_train_twos = x_train[y_train.flatten() == 2]\n",
    "x_train_threes = x_train[y_train.flatten() == 3]\n",
    "x_train_fours = x_train[y_train.flatten() == 4]\n",
    "x_train_fives = x_train[y_train.flatten() == 5]\n",
    "\n",
    "y_train_zeros = y_train[y_train.flatten() == 0]\n",
    "y_train_ones = y_train[y_train.flatten() == 1]\n",
    "y_train_twos = y_train[y_train.flatten() == 2]\n",
    "y_train_threes = y_train[y_train.flatten() == 3]\n",
    "y_train_fours = y_train[y_train.flatten() == 4]\n",
    "y_train_fives = y_train[y_train.flatten() == 5]\n",
    "\n",
    "x_val_zeros = x_val[y_val.flatten() == 0]\n",
    "x_val_ones = x_val[y_val.flatten() == 1]\n",
    "x_val_twos = x_val[y_val.flatten() == 2]\n",
    "x_val_threes = x_val[y_val.flatten() == 3]\n",
    "x_val_fours = x_val[y_val.flatten() == 4]\n",
    "x_val_fives = x_val[y_val.flatten() == 5]\n",
    "\n",
    "y_val_zeros = y_val[y_val.flatten() == 0]\n",
    "y_val_ones = y_val[y_val.flatten() == 1]\n",
    "y_val_twos = y_val[y_val.flatten() == 2]\n",
    "y_val_threes = y_val[y_val.flatten() == 3]\n",
    "y_val_fours = y_val[y_val.flatten() == 4]\n",
    "y_val_fives = y_val[y_val.flatten() == 5]\n",
    "\n",
    "plt.imshow(x_train_zeros[50])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train_threes, x_train_fours, x_train_fives))\n",
    "y_train = np.concatenate((y_train_threes, y_train_fours, y_train_fives))\n",
    "x_val = np.concatenate((x_val_threes, x_val_fours, x_val_fives))\n",
    "y_val = np.concatenate((y_val_threes, y_val_fours, y_val_fives))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illumination Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "illumination_processing = IlluminationPreprocessing()\n",
    "illuminated_list = illumination_processing.process_images_loops(x_train)\n",
    "illuminated_train = [t[0] for t in illuminated_list]\n",
    "illuminated_train_mask = [t[1] for t in illuminated_list]\n",
    "\n",
    "illuminated_list_val = illumination_processing.process_images_loops(x_val)\n",
    "illuminated_val = [t[0] for t in illuminated_list_val]\n",
    "illuminated_val_mask = [t[1] for t in illuminated_list_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illuminated_train shape: (1445, 320, 320)\n",
      "illuminated_train_mask shape: (1445, 320, 320)\n",
      "illuminated_val shape: (188, 320, 320)\n",
      "illuminated_val_mask shape: (188, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "illuminated_train = np.array(illuminated_train)\n",
    "illuminated_train_mask = np.array(illuminated_train_mask)\n",
    "illuminated_val = np.array(illuminated_val)\n",
    "illuminated_val_mask = np.array(illuminated_val_mask)\n",
    "\n",
    "print(f\"illuminated_train shape: {illuminated_train.shape}\")\n",
    "print(f\"illuminated_train_mask shape: {illuminated_train_mask.shape}\")\n",
    "print(f\"illuminated_val shape: {illuminated_val.shape}\")\n",
    "print(f\"illuminated_val_mask shape: {illuminated_val_mask.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned_train shape: (1445, 320, 320)\n",
      "aligned_val shape: (188, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "image_aligner = ImageAligner()\n",
    "\n",
    "aligned_train = image_aligner.align_image(illuminated_train)\n",
    "aligned_val = image_aligner.align_image(illuminated_val)\n",
    "\n",
    "print(f\"aligned_train shape: {aligned_train.shape}\")\n",
    "print(f\"aligned_val shape: {aligned_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection = EdgeDetection(method=\"canny\")\n",
    "edge_detected_train = edge_detection.process(illuminated_train)\n",
    "edge_detected_val = edge_detection.process(illuminated_val)\n",
    "\n",
    "print(f\"edge_detected_train shape: {edge_detected_train.shape}\")\n",
    "print(f\"edge_detected_val shape: {edge_detected_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction And Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca features train shape: (1445, 0)\n",
      "pca features val shape: (188, 0)\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "feature_selector = FeatureSelector()\n",
    "\n",
    "pca_features_train = np.zeros((x_train.shape[0],0))\n",
    "pca_features_val = np.zeros((x_val.shape[0],0))\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hog Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features_train = feature_extractor.extract_hog_features(aligned_train)\n",
    "hog_features_val = feature_extractor.extract_hog_features(aligned_val)\n",
    "\n",
    "pca_hog_features_train = feature_selector.extract_pca_features(hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hog_features_val = feature_selector.extract_pca_features(hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hog_features_val.shape}\")\n",
    "\n",
    "# print(f\"hog pca features train shape: {pca_hog_features_train.shape}\")\n",
    "# print(f\"hog pca features val shape: {pca_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_features_train = feature_extractor.extract_lbp_features(illuminated_train)\n",
    "lbp_features_val = feature_extractor.extract_lbp_features(illuminated_val)\n",
    "\n",
    "pca_lbp_features_train = feature_selector.extract_pca_features(lbp_features_train,load=False, num_pca_components=0.95)\n",
    "pca_lbp_features_val = feature_selector.extract_pca_features(lbp_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_lbp_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_lbp_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {lbp_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"lbp pca features train shape: {pca_lbp_features_train.shape}\")\n",
    "print(f\"lbp pca features val shape: {pca_lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images_train = np.zeros((x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "gray_images_val = np.zeros((x_val.shape[0], x_val.shape[1], x_val.shape[2]))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    gray_images_train[i] = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "for i in range(x_val.shape[0]):\n",
    "    gray_images_val[i] = cv2.cvtColor(x_val[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift_features_train = feature_extractor.extract_sift_features(illuminated_train)\n",
    "sift_features_val = feature_extractor.extract_sift_features(illuminated_val)\n",
    "\n",
    "\n",
    "pca_sift_features_train = feature_selector.extract_pca_features(sift_features_train,load=False, num_pca_components=0.95)\n",
    "pca_sift_features_val = feature_selector.extract_pca_features(sift_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_sift_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_sift_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {sift_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {sift_features_val.shape}\")\n",
    "\n",
    "print(f\"sift pca features train shape: {pca_sift_features_train.shape}\")\n",
    "print(f\"sift pca features val shape: {pca_sift_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAISY Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daisy_features_train = feature_extractor.extract_daisy_features(aligned_train)\n",
    "daisy_features_val = feature_extractor.extract_daisy_features(aligned_val)\n",
    "\n",
    "pca_daisy_features_train = feature_selector.extract_pca_features(daisy_features_train,load=False, num_pca_components=0.95)\n",
    "pca_daisy_features_val = feature_selector.extract_pca_features(daisy_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {daisy_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pca_daisy_features_train, open(\"pca_daisy_features_train.pkl\", \"wb\"))\n",
    "pickle.dump(pca_daisy_features_val, open(\"pca_daisy_features_val.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy pca features train shape: (1445, 25)\n",
      "daisy pca features val shape: (188, 25)\n",
      "pca features train shape: (1445, 25)\n",
      "pca features val shape: (188, 25)\n"
     ]
    }
   ],
   "source": [
    "pca_daisy_features_train = pickle.load(open(\"pca_daisy_features_train.pkl\", \"rb\"))\n",
    "pca_daisy_features_val = pickle.load(open(\"pca_daisy_features_val.pkl\", \"rb\"))\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Descriptor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_features_train = feature_extractor.extract_fourier_descriptor_features(illuminated_train)\n",
    "fd_features_val = feature_extractor.extract_fourier_descriptor_features(illuminated_val)\n",
    "\n",
    "pca_fd_features_train = feature_selector.extract_pca_features(fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_fd_features_val = feature_selector.extract_pca_features(fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_fd_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {fd_features_val.shape}\")\n",
    "\n",
    "print(f\"fd pca features train shape: {pca_fd_features_train.shape}\")\n",
    "print(f\"fd pca features val shape: {pca_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_features_train = feature_extractor.extract_orb_features(illuminated_train)\n",
    "orb_features_val = feature_extractor.extract_orb_features(illuminated_val)\n",
    "\n",
    "pca_orb_features_train = feature_selector.extract_pca_features(orb_features_train,load=False, num_pca_components=0.95)\n",
    "pca_orb_features_val = feature_selector.extract_pca_features(orb_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_orb_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_orb_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {orb_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {orb_features_val.shape}\")\n",
    "\n",
    "print(f\"orb pca features train shape: {pca_orb_features_train.shape}\")\n",
    "print(f\"orb pca features val shape: {pca_orb_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RI HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_hog_features_train = feature_extractor.RI_HOG(illuminated_train_mask)\n",
    "ri_hog_features_val = feature_extractor.RI_HOG(illuminated_val_mask)\n",
    "\n",
    "pca_ri_hog_features_train = feature_selector.extract_pca_features(ri_hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_ri_hog_features_val = feature_selector.extract_pca_features(ri_hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_ri_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_ri_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {ri_hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"ri_hog pca features train shape: {pca_ri_hog_features_train.shape}\")\n",
    "print(f\"ri_hog pca features val shape: {pca_ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hu moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moment_features_train = feature_extractor.extract_hu_moments_features(illuminated_train_mask)\n",
    "hu_moment_features_val = feature_extractor.extract_hu_moments_features(illuminated_val_mask)\n",
    "\n",
    "pca_hu_moment_features_train = feature_selector.extract_pca_features(hu_moment_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hu_moment_features_val = feature_selector.extract_pca_features(hu_moment_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hu_moment_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hu_moment_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hu_moment_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"hu_moment pca features train shape: {pca_hu_moment_features_train.shape}\")\n",
    "print(f\"hu_moment pca features val shape: {pca_hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convex_hull_features_train, max_length_convex_hull = feature_extractor.extract_convex_hull_features(aligned_train)\n",
    "convex_hull_features_val,_ = feature_extractor.extract_convex_hull_features(aligned_val, max_length_convex_hull)\n",
    "\n",
    "print(f\"extracted_features shape: {convex_hull_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {convex_hull_features_val.shape}\")\n",
    "\n",
    "pca_convex_hull_features_train = feature_selector.extract_pca_features(convex_hull_features_train,load=False, num_pca_components=0.95)\n",
    "pca_convex_hull_features_val = feature_selector.extract_pca_features(convex_hull_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_convex_hull_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_convex_hull_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"convex_hull pca features train shape: {pca_convex_hull_features_train.shape}\")\n",
    "print(f\"convex_hull pca features val shape: {pca_convex_hull_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliiptical fourier descriptors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyefd.py:58: RuntimeWarning: invalid value encountered in divide\n",
      "  phi = (2 * np.pi * t) / T\n",
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyefd.py:151: RuntimeWarning: invalid value encountered in divide\n",
      "  coeffs /= np.abs(size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_features shape: (1445, 80)\n",
      "extracted_features_val shape: (188, 80)\n",
      "Creating new PCA model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Senior II\\Pattern Recognition\\Project\\Project-Pattern-Recognition\\main.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y144sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mextracted_features shape: \u001b[39m\u001b[39m{\u001b[39;00melliptical_fd_features_train\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y144sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mextracted_features_val shape: \u001b[39m\u001b[39m{\u001b[39;00melliptical_fd_features_val\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y144sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pca_elliptic_fd_features_train \u001b[39m=\u001b[39m feature_selector\u001b[39m.\u001b[39;49mextract_pca_features(elliptical_fd_features_train,load\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, num_pca_components\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y144sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pca_elliptic_fd_features_val \u001b[39m=\u001b[39m feature_selector\u001b[39m.\u001b[39mextract_pca_features(elliptical_fd_features_val,load\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_pca_components\u001b[39m=\u001b[39m\u001b[39m0.95\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y144sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pca_features_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((pca_features_train, pca_elliptic_fd_features_train), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Senior II\\Pattern Recognition\\Project\\Project-Pattern-Recognition\\feature_selection\\feature_selection.py:29\u001b[0m, in \u001b[0;36mFeatureSelector.extract_pca_features\u001b[1;34m(self, images, load, num_pca_components)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCreating new PCA model...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components \u001b[39m=\u001b[39m num_pca_components, svd_solver \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m pca\u001b[39m.\u001b[39;49mfit(image_vectors)\n\u001b[0;32m     31\u001b[0m pca_features \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(image_vectors)\n\u001b[0;32m     33\u001b[0m pca_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pca_features)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:435\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 435\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    436\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 485\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    486\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    487\u001b[0m )\n\u001b[0;32m    489\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    914\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    915\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    916\u001b[0m         )\n\u001b[0;32m    918\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 919\u001b[0m         _assert_all_finite(\n\u001b[0;32m    920\u001b[0m             array,\n\u001b[0;32m    921\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    922\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    923\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    924\u001b[0m         )\n\u001b[0;32m    926\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "elliptical_fd_features_train = feature_extractor.extract_efds_features(aligned_train)\n",
    "elliptical_fd_features_val = feature_extractor.extract_efds_features(aligned_val)\n",
    "\n",
    "print(f\"extracted_features shape: {elliptical_fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {elliptical_fd_features_val.shape}\")\n",
    "\n",
    "pca_elliptic_fd_features_train = feature_selector.extract_pca_features(elliptical_fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_elliptic_fd_features_val = feature_selector.extract_pca_features(elliptical_fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_elliptic_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_elliptic_fd_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"elliptic_fd pca features train shape: {pca_elliptic_fd_features_train.shape}\")\n",
    "print(f\"elliptic_fd pca features val shape: {pca_elliptic_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_features_train shape: (1445, 34)\n",
      "pca_features_val shape: (188, 34)\n"
     ]
    }
   ],
   "source": [
    "# # PCA FEATURES\n",
    "\n",
    "# pca_features_train = feature_selector.extract_pca_features(extracted_features, load=False, num_pca_components=0.85)\n",
    "# pca_features_val = feature_selector.extract_pca_features(extracted_features_val, load=True, num_pca_components=0.85)\n",
    "\n",
    "print(f\"pca_features_train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca_features_val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the PCA extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_train = (pca_features_train - extracted_features_train_mean) /extracted_features_train_std\n",
    "pca_features_val = (pca_features_val - extracted_features_train_mean) /extracted_features_train_std\n",
    "\n",
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: SVM Train\n",
      "Accuracy: 78.13%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: SVM VALIDATION\n",
      "Accuracy: 66.49%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: KNN Train\n",
      "Accuracy: 84.64%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: KNN VALIDATION\n",
      "Accuracy: 60.64%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Senior II\\Pattern Recognition\\Project\\Project-Pattern-Recognition\\model_selection\\model_selection.py:139: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(self.x_train, self.y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: Ensemble Train\n",
      "Accuracy: 100.0%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: Ensemble VALIDATION\n",
      "Accuracy: 70.74%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: AdaBoost Train\n",
      "Accuracy: 58.55%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: AdaBoost VALIDATION\n",
      "Accuracy: 52.66%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_selection = ModelSelection(pca_features_train, y_train, pca_features_val, y_val)\n",
    "\n",
    "svm, pred_train, pred_val = model_selection.SVM()\n",
    "performance_analysis = PerformanceAnalysis('SVM Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('SVM VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "performance_analysis = PerformanceAnalysis('KNN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('KNN VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "ensemble, pred_train, pred_val = model_selection.Ensemble()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "adaboost, pred_train, pred_val = model_selection.AdaBoost()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 34\n",
      "output_dim: 6\n",
      "x_train: (1445, 34)\n",
      "y_train: (1445, 1)\n",
      "y_onehot: (1445, 6)\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 1s 7ms/step - loss: 1.6728 - accuracy: 0.5938 - val_loss: 1.4085 - val_accuracy: 0.6649\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0836 - accuracy: 0.7474 - val_loss: 1.2603 - val_accuracy: 0.6809\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.8682 - accuracy: 0.8125 - val_loss: 1.1341 - val_accuracy: 0.7234\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.7333 - accuracy: 0.8408 - val_loss: 1.1264 - val_accuracy: 0.6968\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.8789 - val_loss: 1.0271 - val_accuracy: 0.7021\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.9176 - val_loss: 0.9989 - val_accuracy: 0.7340\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.9260 - val_loss: 1.0036 - val_accuracy: 0.7181\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.9412 - val_loss: 1.1445 - val_accuracy: 0.7128\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.9502 - val_loss: 1.0193 - val_accuracy: 0.7553\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.9522 - val_loss: 1.0770 - val_accuracy: 0.7340\n",
      "46/46 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Test accuracy: 0.7340425252914429\n",
      "Test loss: 1.0769774913787842\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-05-13 22:16:56         1897\n",
      "metadata.json                                  2023-05-13 22:16:56           64\n",
      "variables.h5                                   2023-05-13 22:16:56      2665816\n",
      "========================================\n",
      "Model: ANN Train\n",
      "Accuracy: 97.85%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: ANN Val\n",
      "Accuracy: 73.4%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ann, pred_train, pred_val = model_selection.ANN(input_dim=pca_features_train.shape[1], \n",
    "                                                output_dim=6)\n",
    "performance_analysis = PerformanceAnalysis('ANN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('ANN Val', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ba3basa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Define CUDA kernel for reflection removal\n",
    "mod = SourceModule()\n",
    "\n",
    "# Load input image\n",
    "img_path = \"input.jpg\"\n",
    "img = cv2.imread(img_path).astype(np.float32) / 255.0\n",
    "\n",
    "# Allocate memory on GPU\n",
    "img_gpu = cuda.mem_alloc(img.nbytes)\n",
    "cuda.memcpy_htod(img_gpu, img)\n",
    "\n",
    "# Define block and grid sizes for CUDA kernel\n",
    "block_size = (16, 16, 1)\n",
    "grid_size = ((img.shape[0] - 1) // block_size[0] + 1, (img.shape[1] - 1) // block_size[1] + 1, 1)\n",
    "\n",
    "# Call CUDA kernel for reflection removal\n",
    "remove_reflection = mod.get_function(\"remove_reflection\")\n",
    "remove_reflection(img_gpu, np.int32(img.shape[1]), np.int32(img.shape[0]), np.int32(img.shape[2]), block=block_size, grid=grid_size)\n",
    "\n",
    "# Copy output image from GPU to CPU\n",
    "cuda.memcpy_dtoh(img, img_gpu)\n",
    "\n",
    "# Save output image\n",
    "output_path = \"output.jpg\"\n",
    "cv2.imwrite(output_path, img * 255.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
