{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from dataloader.dataloader import DataLoader\n",
    "from preprocessing.clustering_segmentation import ClusteringSegmentation\n",
    "from preprocessing.edge_detection import EdgeDetection\n",
    "from preprocessing.image_restoration import ImageRestorer\n",
    "from preprocessing.preproccessing import ImagePreprocessor\n",
    "from preprocessing.region_segmentation import RegionBasedSegmentation\n",
    "from preprocessing.threshold_segmentation import ThresholdSegmentation\n",
    "from feature_extraction.feature_extraction import FeatureExtractor\n",
    "from feature_selection.feature_selection import FeatureSelector\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Path('./data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from files\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[100])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_segmentation = ClusteringSegmentation(method='kmeans', n_clusters=3, compactness=30.0, sigma=1.0)\n",
    "plt.imshow(clustering_segmentation.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection = EdgeDetection(method='sobel')\n",
    "#method: for roberts and canny: image must be 2D\n",
    "plt.imshow(edge_detection.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_restorer = ImageRestorer(method='median')\n",
    "#'mean_rectangular', 'gaussian', 'adaptive' and 'wiener' generate an error\n",
    "plt.imshow(image_restorer.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preprocessor = ImagePreprocessor(method = 'CLAHE')\n",
    "# method = 'log' generates an error\n",
    "plt.imshow(image_preprocessor.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_based_segmentation = RegionBasedSegmentation(method='region_merging')\n",
    "# method: 'region_splitting' generates an error\n",
    "plt.imshow(region_based_segmentation.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog_features shape: (10, 12800)\n",
      "hog_features: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0.00000000e+00 2.58532313e-04 3.37762585e-04 ... 9.99518592e-01\n",
      " 9.99999996e-01 9.99999999e-01]\n",
      "0.9999999987499999\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# # HOG FEATURES\n",
    "hog_features = feature_extractor.extract_hog_features(rgb2gray(x_train[:10]))\n",
    "print(f\"hog_features shape: {hog_features.shape}\")\n",
    "print(f\"hog_features: {hog_features}\")\n",
    "print(np.unique(hog_features))\n",
    "print(np.max(hog_features))\n",
    "\n",
    "# # LCP FEATURES\n",
    "# lbp_features = []\n",
    "# for i in range(10):\n",
    "#     lbp_features.append(feature_extractor.extract_lbp_features(rgb2gray(x_train[i])))\n",
    "# lbp_features = np.array(lbp_features)\n",
    "# print(f\"lbp_features shape: {lbp_features.shape}\")\n",
    "\n",
    "\n",
    "# sift_features = feature_extractor.extract_sift_features(x_train[:10])\n",
    "# print(f\"sift_features shape: {sift_features.shape}\")\n",
    "\n",
    "# FOURIER DESCRIPTOR FEATURES (error)\n",
    "# fourier_descriptor_features = []\n",
    "# for i in range(10):\n",
    "#     fourier_descriptor_features.append(feature_extractor.extract_fourier_descriptor_features(X_train[i]))\n",
    "# fourier_descriptor_features = np.array(fourier_descriptor_features)\n",
    "# print(f\"fourier_descriptor_features shape: {fourier_descriptor_features.shape}\")\n",
    "\n",
    "# SURF FEATURES (error)\n",
    "\n",
    "# surf_features = feature_extractor.extract_surf_features(x_train[0:10])\n",
    "# print(f\"surf_features shape: {surf_features.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = FeatureSelector()\n",
    "\n",
    "# PCA FEATURES\n",
    "gray_imgs = rgb2gray(x_train)\n",
    "\n",
    "pca_features =  feature_selector.extract_pca_features(gray_imgs,load=True)\n",
    "print(f\"pca_features shape: {pca_features.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_labels is just for trial here\n",
    "true_labels = np.concatenate((np.zeros(10), np.ones(10) * 3))\n",
    "model_selection = ModelSelection(\n",
    "    hog_features[:15], true_labels[:15], hog_features[15:], true_labels[15:]\n",
    ")\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "print(pred_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_analysis = PerformanceAnalysis('KNN', pred_train, true_labels[15:])\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
