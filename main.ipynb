{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from dataloader.dataloader import DataLoader\n",
    "from preprocessing.clustering_segmentation import ClusteringSegmentation\n",
    "from preprocessing.edge_detection import EdgeDetection\n",
    "from preprocessing.image_restoration import ImageRestorer\n",
    "from preprocessing.preproccessing import ImagePreprocessor\n",
    "from preprocessing.region_segmentation import RegionBasedSegmentation\n",
    "from preprocessing.threshold_segmentation import ThresholdSegmentation\n",
    "from feature_extraction.feature_extraction import FeatureExtractor\n",
    "from feature_selection.feature_selection import FeatureSelector\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
    "from preprocessing.image_aligner import ImageAligner\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Path('./data'))\n",
    "\n",
    "# Load Data from files\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data(data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illumination Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illumination_processing = IlluminationPreprocessing()\n",
    "illuminated_list = illumination_processing.process_images_loops(x_train)\n",
    "illuminated_train = [t[0] for t in illuminated_list]\n",
    "illuminated_train_mask = [t[1] for t in illuminated_list]\n",
    "\n",
    "illuminated_list_val = illumination_processing.process_images_loops(x_val)\n",
    "illuminated_val = [t[0] for t in illuminated_list_val]\n",
    "illuminated_val_mask = [t[1] for t in illuminated_list_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illuminated_train = np.array(illuminated_train)\n",
    "illuminated_train_mask = np.array(illuminated_train_mask)\n",
    "illuminated_val = np.array(illuminated_val)\n",
    "illuminated_val_mask = np.array(illuminated_val_mask)\n",
    "\n",
    "print(f\"illuminated_train shape: {illuminated_train.shape}\")\n",
    "print(f\"illuminated_train_mask shape: {illuminated_train_mask.shape}\")\n",
    "print(f\"illuminated_val shape: {illuminated_val.shape}\")\n",
    "print(f\"illuminated_val_mask shape: {illuminated_val_mask.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_aligner = ImageAligner()\n",
    "\n",
    "aligned_train = image_aligner.align_image(illuminated_train)\n",
    "aligned_val = image_aligner.align_image(illuminated_val)\n",
    "\n",
    "print(f\"aligned_train shape: {aligned_train.shape}\")\n",
    "print(f\"aligned_val shape: {aligned_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(aligned_train))\n",
    "print(index)\n",
    "plt.imshow(aligned_train[index])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection = EdgeDetection(method=\"canny\")\n",
    "edge_detected_train = edge_detection.process(illuminated_train)\n",
    "edge_detected_val = edge_detection.process(illuminated_val)\n",
    "\n",
    "print(f\"edge_detected_train shape: {edge_detected_train.shape}\")\n",
    "print(f\"edge_detected_val shape: {edge_detected_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction And Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "feature_selector = FeatureSelector()\n",
    "\n",
    "pca_features_train = np.zeros((x_train.shape[0],0))\n",
    "pca_features_val = np.zeros((x_val.shape[0],0))\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hog Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features_train = feature_extractor.extract_hog_features(aligned_train)\n",
    "hog_features_val = feature_extractor.extract_hog_features(aligned_val)\n",
    "\n",
    "pca_hog_features_train = feature_selector.extract_pca_features(hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hog_features_val = feature_selector.extract_pca_features(hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hog_features_val.shape}\")\n",
    "\n",
    "# print(f\"hog pca features train shape: {pca_hog_features_train.shape}\")\n",
    "# print(f\"hog pca features val shape: {pca_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_features_train = feature_extractor.extract_lbp_features(illuminated_train)\n",
    "lbp_features_val = feature_extractor.extract_lbp_features(illuminated_val)\n",
    "\n",
    "pca_lbp_features_train = feature_selector.extract_pca_features(lbp_features_train,load=False, num_pca_components=0.95)\n",
    "pca_lbp_features_val = feature_selector.extract_pca_features(lbp_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_lbp_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_lbp_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {lbp_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"lbp pca features train shape: {pca_lbp_features_train.shape}\")\n",
    "print(f\"lbp pca features val shape: {pca_lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images_train = np.zeros((x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "gray_images_val = np.zeros((x_val.shape[0], x_val.shape[1], x_val.shape[2]))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    gray_images_train[i] = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "for i in range(x_val.shape[0]):\n",
    "    gray_images_val[i] = cv2.cvtColor(x_val[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift_features_train = feature_extractor.extract_sift_features(illuminated_train)\n",
    "sift_features_val = feature_extractor.extract_sift_features(illuminated_val)\n",
    "\n",
    "\n",
    "pca_sift_features_train = feature_selector.extract_pca_features(sift_features_train,load=False, num_pca_components=0.95)\n",
    "pca_sift_features_val = feature_selector.extract_pca_features(sift_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_sift_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_sift_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {sift_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {sift_features_val.shape}\")\n",
    "\n",
    "print(f\"sift pca features train shape: {pca_sift_features_train.shape}\")\n",
    "print(f\"sift pca features val shape: {pca_sift_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAISY Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daisy_features_train = feature_extractor.extract_daisy_features(aligned_train)\n",
    "daisy_features_val = feature_extractor.extract_daisy_features(aligned_val)\n",
    "\n",
    "pca_daisy_features_train = feature_selector.extract_pca_features(daisy_features_train,load=False, num_pca_components=0.95)\n",
    "pca_daisy_features_val = feature_selector.extract_pca_features(daisy_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {daisy_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca_daisy_features_train, open(\"pca_daisy_features_train.pkl\", \"wb\"))\n",
    "pickle.dump(pca_daisy_features_val, open(\"pca_daisy_features_val.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_daisy_features_train = pickle.load(open(\"pca_daisy_features_train.pkl\", \"rb\"))\n",
    "pca_daisy_features_val = pickle.load(open(\"pca_daisy_features_val.pkl\", \"rb\"))\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Descriptor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_features_train = feature_extractor.extract_fourier_descriptor_features(illuminated_train)\n",
    "fd_features_val = feature_extractor.extract_fourier_descriptor_features(illuminated_val)\n",
    "\n",
    "pca_fd_features_train = feature_selector.extract_pca_features(fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_fd_features_val = feature_selector.extract_pca_features(fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_fd_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {fd_features_val.shape}\")\n",
    "\n",
    "print(f\"fd pca features train shape: {pca_fd_features_train.shape}\")\n",
    "print(f\"fd pca features val shape: {pca_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_features_train = feature_extractor.extract_orb_features(illuminated_train)\n",
    "orb_features_val = feature_extractor.extract_orb_features(illuminated_val)\n",
    "\n",
    "pca_orb_features_train = feature_selector.extract_pca_features(orb_features_train,load=False, num_pca_components=0.95)\n",
    "pca_orb_features_val = feature_selector.extract_pca_features(orb_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_orb_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_orb_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {orb_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {orb_features_val.shape}\")\n",
    "\n",
    "print(f\"orb pca features train shape: {pca_orb_features_train.shape}\")\n",
    "print(f\"orb pca features val shape: {pca_orb_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RI HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_hog_features_train = feature_extractor.RI_HOG(illuminated_train_mask)\n",
    "ri_hog_features_val = feature_extractor.RI_HOG(illuminated_val_mask)\n",
    "\n",
    "pca_ri_hog_features_train = feature_selector.extract_pca_features(ri_hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_ri_hog_features_val = feature_selector.extract_pca_features(ri_hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_ri_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_ri_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {ri_hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"ri_hog pca features train shape: {pca_ri_hog_features_train.shape}\")\n",
    "print(f\"ri_hog pca features val shape: {pca_ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hu moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moment_features_train = feature_extractor.extract_hu_moments_features(illuminated_train_mask)\n",
    "hu_moment_features_val = feature_extractor.extract_hu_moments_features(illuminated_val_mask)\n",
    "\n",
    "pca_hu_moment_features_train = feature_selector.extract_pca_features(hu_moment_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hu_moment_features_val = feature_selector.extract_pca_features(hu_moment_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hu_moment_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hu_moment_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hu_moment_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"hu_moment pca features train shape: {pca_hu_moment_features_train.shape}\")\n",
    "print(f\"hu_moment pca features val shape: {pca_hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convex_hull_features_train, max_length_convex_hull = feature_extractor.extract_convex_hull_features(aligned_train)\n",
    "convex_hull_features_val,_ = feature_extractor.extract_convex_hull_features(aligned_val, max_length_convex_hull)\n",
    "\n",
    "print(f\"extracted_features shape: {convex_hull_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {convex_hull_features_val.shape}\")\n",
    "\n",
    "pca_convex_hull_features_train = feature_selector.extract_pca_features(convex_hull_features_train,load=False, num_pca_components=0.95)\n",
    "pca_convex_hull_features_val = feature_selector.extract_pca_features(convex_hull_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_convex_hull_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_convex_hull_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"convex_hull pca features train shape: {pca_convex_hull_features_train.shape}\")\n",
    "print(f\"convex_hull pca features val shape: {pca_convex_hull_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliiptical fourier descriptors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptical_fd_features_train = feature_extractor.elliptical_fourier_descriptors(aligned_train)\n",
    "elliptical_fd_features_val = feature_extractor.elliptical_fourier_descriptors(aligned_val)\n",
    "\n",
    "print(f\"extracted_features shape: {elliptical_fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {elliptical_fd_features_val.shape}\")\n",
    "\n",
    "pca_elliptic_fd_features_train = feature_selector.extract_pca_features(elliptical_fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_elliptic_fd_features_val = feature_selector.extract_pca_features(elliptical_fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_elliptic_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_elliptic_fd_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"elliptic_fd pca features train shape: {pca_elliptic_fd_features_train.shape}\")\n",
    "print(f\"elliptic_fd pca features val shape: {pca_elliptic_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA FEATURES\n",
    "\n",
    "# pca_features_train = feature_selector.extract_pca_features(extracted_features, load=False, num_pca_components=0.85)\n",
    "# pca_features_val = feature_selector.extract_pca_features(extracted_features_val, load=True, num_pca_components=0.85)\n",
    "\n",
    "print(f\"pca_features_train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca_features_val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the PCA extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_train = (pca_features_train - extracted_features_train_mean) /extracted_features_train_std\n",
    "pca_features_val = (pca_features_val - extracted_features_train_mean) /extracted_features_train_std\n",
    "\n",
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: SVM Train\n",
      "Accuracy: 81.42%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: SVM VALIDATION\n",
      "Accuracy: 76.36%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n",
      "========================================\n",
      "Model: KNN Train\n",
      "Accuracy: 85.55%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: KNN VALIDATION\n",
      "Accuracy: 67.12%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n",
      "========================================\n",
      "Model: Ensemble Train\n",
      "Accuracy: 100.0%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: Ensemble VALIDATION\n",
      "Accuracy: 76.36%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n",
      "========================================\n",
      "Model: AdaBoost Train\n",
      "Accuracy: 53.89%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: AdaBoost VALIDATION\n",
      "Accuracy: 51.36%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_selection = ModelSelection(pca_features_train, y_train, pca_features_val, y_val)\n",
    "\n",
    "svm, pred_train, pred_val = model_selection.SVM()\n",
    "performance_analysis = PerformanceAnalysis('SVM Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('SVM VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "performance_analysis = PerformanceAnalysis('KNN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('KNN VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "ensemble, pred_train, pred_val = model_selection.Ensemble()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "adaboost, pred_train, pred_val = model_selection.AdaBoost()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 76\n",
      "output_dim: 6\n",
      "x_train: (1453, 76)\n",
      "y_train: (1453,)\n",
      "y_onehot: (1453, 6)\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 1s 9ms/step - loss: 2.2095 - accuracy: 0.6173 - val_loss: 1.6866 - val_accuracy: 0.7310\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4168 - accuracy: 0.7777 - val_loss: 1.3503 - val_accuracy: 0.7582\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0954 - accuracy: 0.8307 - val_loss: 1.1183 - val_accuracy: 0.7690\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.8390 - accuracy: 0.8906 - val_loss: 0.9974 - val_accuracy: 0.7962\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.6875 - accuracy: 0.9043 - val_loss: 0.8999 - val_accuracy: 0.8098\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.5708 - accuracy: 0.9236 - val_loss: 0.8781 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.9353 - val_loss: 0.8320 - val_accuracy: 0.7935\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.9470 - val_loss: 0.8156 - val_accuracy: 0.7799\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.9532 - val_loss: 0.8732 - val_accuracy: 0.7636\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.9518 - val_loss: 0.8118 - val_accuracy: 0.7935\n",
      "46/46 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Test accuracy: 0.79347825050354\n",
      "Test loss: 0.8117601871490479\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-05-14 01:07:32         1893\n",
      "metadata.json                                  2023-05-14 01:07:32           64\n",
      "variables.h5                                   2023-05-14 01:07:32      2917816\n",
      "========================================\n",
      "Model: ANN Train\n",
      "Accuracy: 98.28%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: ANN Val\n",
      "Accuracy: 79.35%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ann, pred_train, pred_val = model_selection.ANN(input_dim=pca_features_train.shape[1], \n",
    "                                                output_dim=6)\n",
    "performance_analysis = PerformanceAnalysis('ANN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('ANN Val', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ba3basa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Define CUDA kernel for reflection removal\n",
    "mod = SourceModule()\n",
    "\n",
    "# Load input image\n",
    "img_path = \"input.jpg\"\n",
    "img = cv2.imread(img_path).astype(np.float32) / 255.0\n",
    "\n",
    "# Allocate memory on GPU\n",
    "img_gpu = cuda.mem_alloc(img.nbytes)\n",
    "cuda.memcpy_htod(img_gpu, img)\n",
    "\n",
    "# Define block and grid sizes for CUDA kernel\n",
    "block_size = (16, 16, 1)\n",
    "grid_size = ((img.shape[0] - 1) // block_size[0] + 1, (img.shape[1] - 1) // block_size[1] + 1, 1)\n",
    "\n",
    "# Call CUDA kernel for reflection removal\n",
    "remove_reflection = mod.get_function(\"remove_reflection\")\n",
    "remove_reflection(img_gpu, np.int32(img.shape[1]), np.int32(img.shape[0]), np.int32(img.shape[2]), block=block_size, grid=grid_size)\n",
    "\n",
    "# Copy output image from GPU to CPU\n",
    "cuda.memcpy_dtoh(img, img_gpu)\n",
    "\n",
    "# Save output image\n",
    "output_path = \"output.jpg\"\n",
    "cv2.imwrite(output_path, img * 255.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
