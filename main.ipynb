{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from dataloader.dataloader import DataLoader\n",
    "from preprocessing.clustering_segmentation import ClusteringSegmentation\n",
    "from preprocessing.edge_detection import EdgeDetection\n",
    "from preprocessing.image_restoration import ImageRestorer\n",
    "from preprocessing.preproccessing import ImagePreprocessor\n",
    "from preprocessing.region_segmentation import RegionBasedSegmentation\n",
    "from preprocessing.threshold_segmentation import ThresholdSegmentation\n",
    "from feature_extraction.feature_extraction import FeatureExtractor\n",
    "from feature_selection.feature_selection import FeatureSelector\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Path('./data'))\n",
    "\n",
    "# Load Data from files\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data(data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1445, 320, 320, 3)\n",
      "y_train shape: (1445, 1)\n",
      "x_test shape: (188, 320, 320, 3)\n",
      "y_test shape: (188,)\n",
      "x_val shape: (188, 320, 320, 3)\n",
      "y_val shape: (188,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 20\n",
    "plt.imshow(x_train[index])\n",
    "plt.show()\n",
    "print(f\"y_train[{index}]: {y_train[index]}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "illumination_processing = IlluminationPreprocessing()\n",
    "illuminated_list = illumination_processing.process_images_loops(x_train)\n",
    "illuminated_train = [t[0] for t in illuminated_list]\n",
    "illuminated_train_mask = [t[1] for t in illuminated_list]\n",
    "\n",
    "illuminated_list_val = illumination_processing.process_images_loops(x_val)\n",
    "illuminated_val = [t[0] for t in illuminated_list_val]\n",
    "illuminated_val_mask = [t[1] for t in illuminated_list_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illuminated_train shape: (1445, 320, 320)\n",
      "illuminated_train_mask shape: (1445, 320, 320)\n",
      "illuminated_val shape: (188, 320, 320)\n",
      "illuminated_val_mask shape: (188, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "illuminated_train = np.array(illuminated_train)\n",
    "illuminated_train_mask = np.array(illuminated_train_mask)\n",
    "illuminated_val = np.array(illuminated_val)\n",
    "illuminated_val_mask = np.array(illuminated_val_mask)\n",
    "\n",
    "print(f\"illuminated_train shape: {illuminated_train.shape}\")\n",
    "print(f\"illuminated_train_mask shape: {illuminated_train_mask.shape}\")\n",
    "print(f\"illuminated_val shape: {illuminated_val.shape}\")\n",
    "print(f\"illuminated_val_mask shape: {illuminated_val_mask.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_detected_train shape: (1445, 320, 320)\n",
      "edge_detected_val shape: (188, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "edge_detection = EdgeDetection(method=\"canny\")\n",
    "edge_detected_train = edge_detection.process(illuminated_train)\n",
    "edge_detected_val = edge_detection.process(illuminated_val)\n",
    "\n",
    "print(f\"edge_detected_train shape: {edge_detected_train.shape}\")\n",
    "print(f\"edge_detected_val shape: {edge_detected_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(0, len(edge_detected_train))\n",
    "plt.imshow(edge_detected_train[index])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preprocessor = ImagePreprocessor()\n",
    "\n",
    "illuminated_train, illuminated_val = image_preprocessor.resize_images(illuminated_train,illuminated_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(illuminated_train[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction And Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "feature_selector = FeatureSelector()\n",
    "\n",
    "pca_features_train = np.zeros((x_train.shape[0],0))\n",
    "pca_features_val = np.zeros((x_val.shape[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca features train shape: (1445, 0)\n",
      "pca features val shape: (188, 0)\n"
     ]
    }
   ],
   "source": [
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hog Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new PCA model...\n",
      "extracted_features shape: (1445, 2880)\n",
      "extracted_features_val shape: (188, 2880)\n",
      "hog pca features train shape: (1445, 292)\n",
      "hog pca features val shape: (188, 292)\n",
      "pca features train shape: (1445, 292)\n",
      "pca features val shape: (188, 292)\n"
     ]
    }
   ],
   "source": [
    "hog_features_train = feature_extractor.extract_hog_features(edge_detected_train)\n",
    "hog_features_val = feature_extractor.extract_hog_features(edge_detected_val)\n",
    "\n",
    "pca_hog_features_train = feature_selector.extract_pca_features(hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hog_features_val = feature_selector.extract_pca_features(hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hog_features_val.shape}\")\n",
    "\n",
    "print(f\"hog pca features train shape: {pca_hog_features_train.shape}\")\n",
    "print(f\"hog pca features val shape: {pca_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_features_train = feature_extractor.extract_lbp_features(illuminated_train)\n",
    "lbp_features_val = feature_extractor.extract_lbp_features(illuminated_val)\n",
    "\n",
    "pca_lbp_features_train = feature_selector.extract_pca_features(lbp_features_train,load=False, num_pca_components=0.95)\n",
    "pca_lbp_features_val = feature_selector.extract_pca_features(lbp_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_lbp_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_lbp_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {lbp_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"lbp pca features train shape: {pca_lbp_features_train.shape}\")\n",
    "print(f\"lbp pca features val shape: {pca_lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images_train = np.zeros((x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "gray_images_val = np.zeros((x_val.shape[0], x_val.shape[1], x_val.shape[2]))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    gray_images_train[i] = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "for i in range(x_val.shape[0]):\n",
    "    gray_images_val[i] = cv2.cvtColor(x_val[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift_features_train = feature_extractor.extract_sift_features(illuminated_train)\n",
    "sift_features_val = feature_extractor.extract_sift_features(illuminated_val)\n",
    "\n",
    "\n",
    "pca_sift_features_train = feature_selector.extract_pca_features(sift_features_train,load=False, num_pca_components=0.95)\n",
    "pca_sift_features_val = feature_selector.extract_pca_features(sift_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_sift_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_sift_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {sift_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {sift_features_val.shape}\")\n",
    "\n",
    "print(f\"sift pca features train shape: {pca_sift_features_train.shape}\")\n",
    "print(f\"sift pca features val shape: {pca_sift_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAISY Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daisy_features_train = feature_extractor.extract_daisy_features(illuminated_train)\n",
    "daisy_features_val = feature_extractor.extract_daisy_features(illuminated_val)\n",
    "\n",
    "pca_daisy_features_train = feature_selector.extract_pca_features(daisy_features_train,load=False, num_pca_components=0.95)\n",
    "pca_daisy_features_val = feature_selector.extract_pca_features(daisy_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {daisy_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Descriptor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_features_train = feature_extractor.extract_fourier_descriptor_features(illuminated_train)\n",
    "fd_features_val = feature_extractor.extract_fourier_descriptor_features(illuminated_val)\n",
    "\n",
    "pca_fd_features_train = feature_selector.extract_pca_features(fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_fd_features_val = feature_selector.extract_pca_features(fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_fd_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {fd_features_val.shape}\")\n",
    "\n",
    "print(f\"fd pca features train shape: {pca_fd_features_train.shape}\")\n",
    "print(f\"fd pca features val shape: {pca_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_features_train = feature_extractor.extract_orb_features(illuminated_train)\n",
    "orb_features_val = feature_extractor.extract_orb_features(illuminated_val)\n",
    "\n",
    "pca_orb_features_train = feature_selector.extract_pca_features(orb_features_train,load=False, num_pca_components=0.95)\n",
    "pca_orb_features_val = feature_selector.extract_pca_features(orb_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_orb_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_orb_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {orb_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {orb_features_val.shape}\")\n",
    "\n",
    "print(f\"orb pca features train shape: {pca_orb_features_train.shape}\")\n",
    "print(f\"orb pca features val shape: {pca_orb_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RI HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_hog_features_train = feature_extractor.RI_HOG(illuminated_train_mask)\n",
    "ri_hog_features_val = feature_extractor.RI_HOG(illuminated_val_mask)\n",
    "\n",
    "pca_ri_hog_features_train = feature_selector.extract_pca_features(ri_hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_ri_hog_features_val = feature_selector.extract_pca_features(ri_hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_ri_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_ri_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {ri_hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"ri_hog pca features train shape: {pca_ri_hog_features_train.shape}\")\n",
    "print(f\"ri_hog pca features val shape: {pca_ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hu moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moment_features_train = feature_extractor.extract_hu_moments_features(illuminated_train_mask)\n",
    "hu_moment_features_val = feature_extractor.extract_hu_moments_features(illuminated_val_mask)\n",
    "\n",
    "pca_hu_moment_features_train = feature_selector.extract_pca_features(hu_moment_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hu_moment_features_val = feature_selector.extract_pca_features(hu_moment_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hu_moment_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hu_moment_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hu_moment_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"hu_moment pca features train shape: {pca_hu_moment_features_train.shape}\")\n",
    "print(f\"hu_moment pca features val shape: {pca_hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convex_hull_features_train = feature_extractor.extract_convex_hull_features(illuminated_train_mask)\n",
    "convex_hull_features_val = feature_extractor.extract_convex_hull_features(illuminated_val_mask)\n",
    "\n",
    "pca_convex_hull_features_train = feature_selector.extract_pca_features(convex_hull_features_train,load=False, num_pca_components=0.95)\n",
    "pca_convex_hull_features_val = feature_selector.extract_pca_features(convex_hull_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_convex_hull_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_convex_hull_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {convex_hull_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {convex_hull_features_val.shape}\")\n",
    "\n",
    "print(f\"convex_hull pca features train shape: {pca_convex_hull_features_train.shape}\")\n",
    "print(f\"convex_hull pca features val shape: {pca_convex_hull_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliiptical fourier descriptors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptical_fd_features_train = feature_extractor.elliptical_fourier_descriptors(illuminated_train_mask)\n",
    "elliptical_fd_features_val = feature_extractor.elliptical_fourier_descriptors(illuminated_val_mask)\n",
    "\n",
    "pca_elliptic_fd_features_train = feature_selector.extract_pca_features(elliptical_fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_elliptic_fd_features_val = feature_selector.extract_pca_features(elliptical_fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_elliptic_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_elliptic_fd_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {elliptical_fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {elliptical_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"elliptic_fd pca features train shape: {pca_elliptic_fd_features_train.shape}\")\n",
    "print(f\"elliptic_fd pca features val shape: {pca_elliptic_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_features_train shape: (1445, 292)\n",
      "pca_features_val shape: (188, 292)\n"
     ]
    }
   ],
   "source": [
    "# # PCA FEATURES\n",
    "\n",
    "# pca_features_train = feature_selector.extract_pca_features(extracted_features, load=False, num_pca_components=0.85)\n",
    "# pca_features_val = feature_selector.extract_pca_features(extracted_features_val, load=True, num_pca_components=0.85)\n",
    "\n",
    "print(f\"pca_features_train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca_features_val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the PCA extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_train = (pca_features_train - extracted_features_train_mean) /extracted_features_train_std\n",
    "pca_features_val = (pca_features_val - extracted_features_train_mean) /extracted_features_train_std\n",
    "\n",
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: SVM Train\n",
      "Accuracy: 100.0%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: SVM VALIDATION\n",
      "Accuracy: 49.47%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0mThis text has default colors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: KNN Train\n",
      "Accuracy: 68.51%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: KNN VALIDATION\n",
      "Accuracy: 39.36%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0mThis text has default colors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Senior II\\Pattern Recognition\\Project\\Project-Pattern-Recognition\\model_selection\\model_selection.py:139: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(self.x_train, self.y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: Ensemble Train\n",
      "Accuracy: 100.0%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: Ensemble VALIDATION\n",
      "Accuracy: 46.28%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0mThis text has default colors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: AdaBoost Train\n",
      "Accuracy: 48.1%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: AdaBoost VALIDATION\n",
      "Accuracy: 43.09%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0mThis text has default colors.\n"
     ]
    }
   ],
   "source": [
    "model_selection = ModelSelection(pca_features_train, y_train, pca_features_val, y_val)\n",
    "\n",
    "svm, pred_train, pred_val = model_selection.SVM()\n",
    "performance_analysis = PerformanceAnalysis('SVM Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('SVM VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "performance_analysis = PerformanceAnalysis('KNN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('KNN VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "ensemble, pred_train, pred_val = model_selection.Ensemble()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "adaboost, pred_train, pred_val = model_selection.AdaBoost()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 292\n",
      "output_dim: 6\n",
      "x_train: (1445, 292)\n",
      "y_train: (1445, 1)\n",
      "y_onehot: (1445, 6)\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 4.8236 - accuracy: 0.3294 - val_loss: 4.0405 - val_accuracy: 0.4894\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8726 - accuracy: 0.8630 - val_loss: 3.1026 - val_accuracy: 0.5585\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8821 - accuracy: 0.9730 - val_loss: 2.6543 - val_accuracy: 0.5957\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2733 - accuracy: 0.9958 - val_loss: 2.2573 - val_accuracy: 0.5585\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.8579 - accuracy: 0.9986 - val_loss: 1.9237 - val_accuracy: 0.5904\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.9972 - val_loss: 1.7745 - val_accuracy: 0.5904\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.9869 - val_loss: 2.0696 - val_accuracy: 0.5266\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.7654 - accuracy: 0.8727 - val_loss: 2.0738 - val_accuracy: 0.5213\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.8588 - accuracy: 0.8900 - val_loss: 2.3800 - val_accuracy: 0.5266\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.6468 - accuracy: 0.9696 - val_loss: 2.1368 - val_accuracy: 0.5691\n",
      "46/46 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Test accuracy: 0.5691489577293396\n",
      "Test loss: 2.136789083480835\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-05-13 19:01:26         1896\n",
      "metadata.json                                  2023-05-13 19:01:26           64\n",
      "variables.h5                                   2023-05-13 19:01:26      4213816\n",
      "========================================\n",
      "Model: ANN Train\n",
      "Accuracy: 99.93%\n",
      "========================================\n",
      "\n",
      "\u001b[31m\n",
      "*****************************************\n",
      "Model: ANN Val\n",
      "Accuracy: 56.91%\n",
      "*****************************************\n",
      "\n",
      "\u001b[0mThis text has default colors.\n"
     ]
    }
   ],
   "source": [
    "ann, pred_train, pred_val = model_selection.ANN(input_dim=pca_features_train.shape[1], \n",
    "                                                output_dim=6)\n",
    "performance_analysis = PerformanceAnalysis('ANN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('ANN Val', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
