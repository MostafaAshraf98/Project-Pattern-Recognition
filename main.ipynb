{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dataloader.dataloader import DataLoader\n",
    "from preprocessing.clustering_segmentation import ClusteringSegmentation\n",
    "from preprocessing.edge_detection import EdgeDetection\n",
    "from preprocessing.image_restoration import ImageRestorer\n",
    "from preprocessing.preproccessing import ImagePreprocessor\n",
    "from preprocessing.region_segmentation import RegionBasedSegmentation\n",
    "from preprocessing.threshold_segmentation import ThresholdSegmentation\n",
    "from feature_extraction.feature_extraction import FeatureExtractor\n",
    "from feature_selection.feature_selection import FeatureSelector\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
    "from preprocessing.image_aligner import ImageAligner\n",
    "from imports import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Path('./data'))\n",
    "\n",
    "# Load Data from files\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data(data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1453, 320, 320, 3)\n",
      "y_train shape: (1453,)\n",
      "x_val shape: (368, 320, 320, 3)\n",
      "y_val shape: (368,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illumination Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "illumination_processing = IlluminationPreprocessing()\n",
    "\n",
    "illuminated_list = illumination_processing.process_images_loops(x_train)\n",
    "illuminated_train = [t[0] for t in illuminated_list]\n",
    "illuminated_train_mask = [t[1] for t in illuminated_list]\n",
    "\n",
    "illuminated_list_val = illumination_processing.process_images_loops(x_val)\n",
    "illuminated_val = [t[0] for t in illuminated_list_val]\n",
    "illuminated_val_mask = [t[1] for t in illuminated_list_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illuminated_train shape: (1453, 320, 320)\n",
      "illuminated_train_mask shape: (1453, 320, 320)\n",
      "illuminated_val shape: (368, 320, 320)\n",
      "illuminated_val_mask shape: (368, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "illuminated_train = np.array(illuminated_train)\n",
    "illuminated_train_mask = np.array(illuminated_train_mask)\n",
    "illuminated_val = np.array(illuminated_val)\n",
    "illuminated_val_mask = np.array(illuminated_val_mask)\n",
    "\n",
    "print(f\"illuminated_train shape: {illuminated_train.shape}\")\n",
    "print(f\"illuminated_train_mask shape: {illuminated_train_mask.shape}\")\n",
    "print(f\"illuminated_val shape: {illuminated_val.shape}\")\n",
    "print(f\"illuminated_val_mask shape: {illuminated_val_mask.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned_train shape: (1453, 320, 320)\n",
      "aligned_val shape: (368, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "image_aligner = ImageAligner()\n",
    "\n",
    "aligned_train = image_aligner.align_image(illuminated_train)\n",
    "aligned_val = image_aligner.align_image(illuminated_val)\n",
    "\n",
    "print(f\"aligned_train shape: {aligned_train.shape}\")\n",
    "print(f\"aligned_val shape: {aligned_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(aligned_train))\n",
    "print(index)\n",
    "plt.imshow(aligned_train[index])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection = EdgeDetection(method=\"canny\")\n",
    "edge_detected_train = edge_detection.process(illuminated_train)\n",
    "edge_detected_val = edge_detection.process(illuminated_val)\n",
    "\n",
    "print(f\"edge_detected_train shape: {edge_detected_train.shape}\")\n",
    "print(f\"edge_detected_val shape: {edge_detected_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction And Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca features train shape: (1453, 0)\n",
      "pca features val shape: (368, 0)\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "feature_selector = FeatureSelector()\n",
    "\n",
    "pca_features_train = np.zeros((x_train.shape[0],0))\n",
    "pca_features_val = np.zeros((x_val.shape[0],0))\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hog Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features_train = feature_extractor.extract_hog_features(aligned_train)\n",
    "hog_features_val = feature_extractor.extract_hog_features(aligned_val)\n",
    "\n",
    "pca_hog_features_train = feature_selector.extract_pca_features(hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hog_features_val = feature_selector.extract_pca_features(hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hog_features_val.shape}\")\n",
    "\n",
    "print(f\"hog pca features train shape: {pca_hog_features_train.shape}\")\n",
    "print(f\"hog pca features val shape: {pca_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_features_train = feature_extractor.extract_lbp_features(illuminated_train)\n",
    "lbp_features_val = feature_extractor.extract_lbp_features(illuminated_val)\n",
    "\n",
    "pca_lbp_features_train = feature_selector.extract_pca_features(lbp_features_train,load=False, num_pca_components=0.95)\n",
    "pca_lbp_features_val = feature_selector.extract_pca_features(lbp_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_lbp_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_lbp_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {lbp_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"lbp pca features train shape: {pca_lbp_features_train.shape}\")\n",
    "print(f\"lbp pca features val shape: {pca_lbp_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images_train = np.zeros((x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "gray_images_val = np.zeros((x_val.shape[0], x_val.shape[1], x_val.shape[2]))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    gray_images_train[i] = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "for i in range(x_val.shape[0]):\n",
    "    gray_images_val[i] = cv2.cvtColor(x_val[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift_features_train = feature_extractor.extract_sift_features(illuminated_train)\n",
    "sift_features_val = feature_extractor.extract_sift_features(illuminated_val)\n",
    "\n",
    "\n",
    "pca_sift_features_train = feature_selector.extract_pca_features(sift_features_train,load=False, num_pca_components=0.95)\n",
    "pca_sift_features_val = feature_selector.extract_pca_features(sift_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_sift_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_sift_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {sift_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {sift_features_val.shape}\")\n",
    "\n",
    "print(f\"sift pca features train shape: {pca_sift_features_train.shape}\")\n",
    "print(f\"sift pca features val shape: {pca_sift_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAISY Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Senior II\\Pattern Recognition\\Project\\Project-Pattern-Recognition\\main.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y225sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m daisy_features_train \u001b[39m=\u001b[39m feature_extractor\u001b[39m.\u001b[39;49mextract_daisy_features(aligned_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y225sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m daisy_features_val \u001b[39m=\u001b[39m feature_extractor\u001b[39m.\u001b[39mextract_daisy_features(aligned_val)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Senior%20II/Pattern%20Recognition/Project/Project-Pattern-Recognition/main.ipynb#Y225sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pca_daisy_features_train \u001b[39m=\u001b[39m feature_selector\u001b[39m.\u001b[39mextract_pca_features(daisy_features_train,load\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_pca_components\u001b[39m=\u001b[39m\u001b[39m0.95\u001b[39m)\n",
      "File \u001b[1;32md:\\Senior II\\Pattern Recognition\\Project\\Project-Pattern-Recognition\\feature_extraction\\feature_extraction.py:148\u001b[0m, in \u001b[0;36mFeatureExtractor.extract_daisy_features\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m    104\u001b[0m descs_features \u001b[39m=\u001b[39m []\n\u001b[0;32m    106\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images:\n\u001b[0;32m    107\u001b[0m     \u001b[39m# descs = daisy(  image, \u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[39m#                 step=180,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[39m# However, keep in mind that increasing these parameters would also increase the \u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# computational cost of the function.\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     descs \u001b[39m=\u001b[39m daisy(  image, \n\u001b[0;32m    149\u001b[0m                     step\u001b[39m=\u001b[39;49m\u001b[39m180\u001b[39;49m,\n\u001b[0;32m    150\u001b[0m                     radius\u001b[39m=\u001b[39;49m\u001b[39m58\u001b[39;49m,\n\u001b[0;32m    151\u001b[0m                     rings\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[0;32m    152\u001b[0m                     histograms\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[0;32m    153\u001b[0m                     orientations\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[0;32m    154\u001b[0m                     visualize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    155\u001b[0m     descs \u001b[39m=\u001b[39m descs\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    156\u001b[0m     descs_features\u001b[39m.\u001b[39mappend(descs)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\feature\\_daisy.py:148\u001b[0m, in \u001b[0;36mdaisy\u001b[1;34m(image, step, radius, rings, histograms, orientations, normalization, sigmas, ring_radii, visualize)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(rings \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    147\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(orientations):\n\u001b[1;32m--> 148\u001b[0m         hist_smooth[i, j, :, :] \u001b[39m=\u001b[39m gaussian(hist[j, :, :], sigma\u001b[39m=\u001b[39;49msigmas[i],\n\u001b[0;32m    149\u001b[0m                                            mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreflect\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    151\u001b[0m \u001b[39m# Assemble descriptor grid.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m theta \u001b[39m=\u001b[39m [\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m pi \u001b[39m*\u001b[39m j \u001b[39m/\u001b[39m histograms \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(histograms)]\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\_shared\\utils.py:348\u001b[0m, in \u001b[0;36mdeprecate_multichannel_kwarg.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m convert[kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmultichannel\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m    347\u001b[0m \u001b[39m# Call the function with the fixed arguments\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\_shared\\filters.py:136\u001b[0m, in \u001b[0;36mgaussian\u001b[1;34m(image, sigma, output, mode, cval, multichannel, preserve_range, truncate, channel_axis)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mif\u001b[39;00m (output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(output\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating)):\n\u001b[0;32m    135\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mProvided output data type is not float\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m \u001b[39mreturn\u001b[39;00m ndi\u001b[39m.\u001b[39;49mgaussian_filter(image, sigma, output\u001b[39m=\u001b[39;49moutput,\n\u001b[0;32m    137\u001b[0m                            mode\u001b[39m=\u001b[39;49mmode, cval\u001b[39m=\u001b[39;49mcval, truncate\u001b[39m=\u001b[39;49mtruncate)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\ndimage\\_filters.py:342\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(axes) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[39mfor\u001b[39;00m axis, sigma, order, mode \u001b[39min\u001b[39;00m axes:\n\u001b[1;32m--> 342\u001b[0m         gaussian_filter1d(\u001b[39minput\u001b[39;49m, sigma, axis, order, output,\n\u001b[0;32m    343\u001b[0m                           mode, cval, truncate)\n\u001b[0;32m    344\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m output\n\u001b[0;32m    345\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\ndimage\\_filters.py:261\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[1;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[0;32m    260\u001b[0m weights \u001b[39m=\u001b[39m _gaussian_kernel1d(sigma, order, lw)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 261\u001b[0m \u001b[39mreturn\u001b[39;00m correlate1d(\u001b[39minput\u001b[39;49m, weights, axis, output, mode, cval, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\ndimage\\_filters.py:133\u001b[0m, in \u001b[0;36mcorrelate1d\u001b[1;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid origin; origin must satisfy \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    130\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    131\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(len(weights)-1) // 2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    132\u001b[0m mode \u001b[39m=\u001b[39m _ni_support\u001b[39m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m--> 133\u001b[0m _nd_image\u001b[39m.\u001b[39;49mcorrelate1d(\u001b[39minput\u001b[39;49m, weights, axis, output, mode, cval,\n\u001b[0;32m    134\u001b[0m                       origin)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "daisy_features_train = feature_extractor.extract_daisy_features(aligned_train)\n",
    "daisy_features_val = feature_extractor.extract_daisy_features(aligned_val)\n",
    "\n",
    "pca_daisy_features_train = feature_selector.extract_pca_features(daisy_features_train,load=False, num_pca_components=0.95)\n",
    "pca_daisy_features_val = feature_selector.extract_pca_features(daisy_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {daisy_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(daisy_features_train, open(\"daisy_features_train.pkl\", \"wb\"))\n",
    "pickle.dump(daisy_features_val, open(\"daisy_features_val.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_train = daisy_features_train\n",
    "pca_features_val = daisy_features_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca_daisy_features_train, open(\"pca_daisy_features_train.pkl\", \"wb\"))\n",
    "pickle.dump(pca_daisy_features_val, open(\"pca_daisy_features_val.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_daisy_features_train = pickle.load(open(\"pca_daisy_features_train.pkl\", \"rb\"))\n",
    "pca_daisy_features_val = pickle.load(open(\"pca_daisy_features_val.pkl\", \"rb\"))\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_daisy_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_daisy_features_val), axis=1)\n",
    "\n",
    "print(f\"daisy pca features train shape: {pca_daisy_features_train.shape}\")\n",
    "print(f\"daisy pca features val shape: {pca_daisy_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Descriptor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_features_train = feature_extractor.extract_fourier_descriptor_features(illuminated_train)\n",
    "fd_features_val = feature_extractor.extract_fourier_descriptor_features(illuminated_val)\n",
    "\n",
    "pca_fd_features_train = feature_selector.extract_pca_features(fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_fd_features_val = feature_selector.extract_pca_features(fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_fd_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {fd_features_val.shape}\")\n",
    "\n",
    "print(f\"fd pca features train shape: {pca_fd_features_train.shape}\")\n",
    "print(f\"fd pca features val shape: {pca_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_features_train = feature_extractor.extract_orb_features(illuminated_train)\n",
    "orb_features_val = feature_extractor.extract_orb_features(illuminated_val)\n",
    "\n",
    "pca_orb_features_train = feature_selector.extract_pca_features(orb_features_train,load=False, num_pca_components=0.95)\n",
    "pca_orb_features_val = feature_selector.extract_pca_features(orb_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_orb_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_orb_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {orb_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {orb_features_val.shape}\")\n",
    "\n",
    "print(f\"orb pca features train shape: {pca_orb_features_train.shape}\")\n",
    "print(f\"orb pca features val shape: {pca_orb_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RI HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_hog_features_train = feature_extractor.RI_HOG(illuminated_train_mask)\n",
    "ri_hog_features_val = feature_extractor.RI_HOG(illuminated_val_mask)\n",
    "\n",
    "pca_ri_hog_features_train = feature_selector.extract_pca_features(ri_hog_features_train,load=False, num_pca_components=0.95)\n",
    "pca_ri_hog_features_val = feature_selector.extract_pca_features(ri_hog_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_ri_hog_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_ri_hog_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {ri_hog_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"ri_hog pca features train shape: {pca_ri_hog_features_train.shape}\")\n",
    "print(f\"ri_hog pca features val shape: {pca_ri_hog_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hu moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moment_features_train = feature_extractor.extract_hu_moments_features(illuminated_train_mask)\n",
    "hu_moment_features_val = feature_extractor.extract_hu_moments_features(illuminated_val_mask)\n",
    "\n",
    "pca_hu_moment_features_train = feature_selector.extract_pca_features(hu_moment_features_train,load=False, num_pca_components=0.95)\n",
    "pca_hu_moment_features_val = feature_selector.extract_pca_features(hu_moment_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_hu_moment_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_hu_moment_features_val), axis=1)\n",
    "\n",
    "print(f\"extracted_features shape: {hu_moment_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"hu_moment pca features train shape: {pca_hu_moment_features_train.shape}\")\n",
    "print(f\"hu_moment pca features val shape: {pca_hu_moment_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convex_hull_features_train, max_length_convex_hull = feature_extractor.extract_convex_hull_features(aligned_train)\n",
    "convex_hull_features_val,_ = feature_extractor.extract_convex_hull_features(aligned_val, max_length_convex_hull)\n",
    "\n",
    "print(f\"extracted_features shape: {convex_hull_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {convex_hull_features_val.shape}\")\n",
    "\n",
    "pca_convex_hull_features_train = feature_selector.extract_pca_features(convex_hull_features_train,load=False, num_pca_components=0.95)\n",
    "pca_convex_hull_features_val = feature_selector.extract_pca_features(convex_hull_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_convex_hull_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_convex_hull_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"convex_hull pca features train shape: {pca_convex_hull_features_train.shape}\")\n",
    "print(f\"convex_hull pca features val shape: {pca_convex_hull_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliiptical fourier descriptors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptical_fd_features_train = feature_extractor.elliptical_fourier_descriptors(aligned_train)\n",
    "elliptical_fd_features_val = feature_extractor.elliptical_fourier_descriptors(aligned_val)\n",
    "\n",
    "print(f\"extracted_features shape: {elliptical_fd_features_train.shape}\")\n",
    "print(f\"extracted_features_val shape: {elliptical_fd_features_val.shape}\")\n",
    "\n",
    "pca_elliptic_fd_features_train = feature_selector.extract_pca_features(elliptical_fd_features_train,load=False, num_pca_components=0.95)\n",
    "pca_elliptic_fd_features_val = feature_selector.extract_pca_features(elliptical_fd_features_val,load=True, num_pca_components=0.95)\n",
    "\n",
    "pca_features_train = np.concatenate((pca_features_train, pca_elliptic_fd_features_train), axis=1)\n",
    "pca_features_val = np.concatenate((pca_features_val, pca_elliptic_fd_features_val), axis=1)\n",
    "\n",
    "\n",
    "print(f\"elliptic_fd pca features train shape: {pca_elliptic_fd_features_train.shape}\")\n",
    "print(f\"elliptic_fd pca features val shape: {pca_elliptic_fd_features_val.shape}\")\n",
    "\n",
    "print(f\"pca features train shape: {pca_features_train.shape}\")\n",
    "print(f\"pca features val shape: {pca_features_val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the PCA extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_train_mean = pca_features_train.mean(axis=0)\n",
    "extracted_features_train_std = pca_features_train.std(axis=0)\n",
    "\n",
    "# save these 2 to files\n",
    "np.save(\"extracted_features_train_mean.npy\", extracted_features_train_mean)\n",
    "np.save(\"extracted_features_train_std.npy\", extracted_features_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_train = (pca_features_train - extracted_features_train_mean) /extracted_features_train_std\n",
    "pca_features_val = (pca_features_val - extracted_features_train_mean) /extracted_features_train_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = ModelSelection(pca_features_train, y_train, pca_features_val, y_val)\n",
    "\n",
    "svm, pred_train, pred_val = model_selection.SVM()\n",
    "performance_analysis = PerformanceAnalysis('SVM Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('SVM VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "performance_analysis = PerformanceAnalysis('KNN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('KNN VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "ensemble, pred_train, pred_val = model_selection.Ensemble()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "adaboost, pred_train, pred_val = model_selection.AdaBoost()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = ModelSelection(pca_features_train, y_train, pca_features_val, y_val)\n",
    "\n",
    "ann, pred_train, pred_val = model_selection.ANN(input_dim=pca_features_train.shape[1], \n",
    "                                                output_dim=6)\n",
    "performance_analysis = PerformanceAnalysis('ANN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('ANN Val', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
