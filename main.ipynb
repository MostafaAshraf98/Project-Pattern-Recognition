{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from dataloader.dataloader import DataLoader\n",
    "from preprocessing.clustering_segmentation import ClusteringSegmentation\n",
    "from preprocessing.edge_detection import EdgeDetection\n",
    "from preprocessing.image_restoration import ImageRestorer\n",
    "from preprocessing.preproccessing import ImagePreprocessor\n",
    "from preprocessing.region_segmentation import RegionBasedSegmentation\n",
    "from preprocessing.threshold_segmentation import ThresholdSegmentation\n",
    "from feature_extraction.feature_extraction import FeatureExtractor\n",
    "from feature_selection.feature_selection import FeatureSelector\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Path('./data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from files\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[100])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_segmentation = ClusteringSegmentation(method='kmeans', n_clusters=3, compactness=30.0, sigma=1.0)\n",
    "plt.imshow(clustering_segmentation.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection = EdgeDetection(method='sobel')\n",
    "#method: for roberts and canny: image must be 2D\n",
    "plt.imshow(edge_detection.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_restorer = ImageRestorer(method='median')\n",
    "#'mean_rectangular', 'gaussian', 'adaptive' and 'wiener' generate an error\n",
    "plt.imshow(image_restorer.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preprocessor = ImagePreprocessor(method = 'CLAHE')\n",
    "# method = 'log' generates an error\n",
    "plt.imshow(image_preprocessor.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_based_segmentation = RegionBasedSegmentation(method='region_merging')\n",
    "# method: 'region_splitting' generates an error\n",
    "plt.imshow(region_based_segmentation.process(x_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.SIFT' object has no attribute 'detectAndComputeMulti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_extractor \u001b[39m=\u001b[39m FeatureExtractor()\n\u001b[0;32m      3\u001b[0m \u001b[39m# # HOG FEATURES\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# hog_features = []\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# #10 images with label = 0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# lbp_features = np.array(lbp_features)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# print(f\"lbp_features shape: {lbp_features.shape}\")\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m sift_features \u001b[39m=\u001b[39m feature_extractor\u001b[39m.\u001b[39;49mextract_sift_features(x_train[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msift_features shape: \u001b[39m\u001b[39m{\u001b[39;00msift_features\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[39m# FOURIER DESCRIPTOR FEATURES (error)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m# fourier_descriptor_features = []\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m# for i in range(10):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# surf_features = feature_extractor.extract_surf_features(x_train[0:10])\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# print(f\"surf_features shape: {surf_features.shape}\")\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\CCE\\Year 4 - Senior 2\\Semester 2\\Pattern\\Project\\Project-Pattern-Recognition\\feature_extraction\\feature_extraction.py:48\u001b[0m, in \u001b[0;36mFeatureExtractor.extract_sift_features\u001b[1;34m(self, images, sift_num_features)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_sift_features\u001b[39m(\u001b[39mself\u001b[39m, images, sift_num_features\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m):\n\u001b[0;32m     46\u001b[0m     \u001b[39m# sift = cv2.xfeatures2d.SIFT_create(128)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     sift \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mSIFT_create(sift_num_features)\n\u001b[1;32m---> 48\u001b[0m     keypoints, sift_features \u001b[39m=\u001b[39m sift\u001b[39m.\u001b[39;49mdetectAndComputeMulti(images, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m sift_features\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.SIFT' object has no attribute 'detectAndComputeMulti'"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# # HOG FEATURES\n",
    "# hog_features = []\n",
    "# #10 images with label = 0\n",
    "# for i in range(10):\n",
    "#     hog_features.append(feature_extractor.extract_hog_features(x_train[i]))\n",
    "# # 10 images with label = 3\n",
    "# for i in range(1000, 1010):\n",
    "#     hog_features.append(feature_extractor.extract_hog_features(x_train[i]))\n",
    "# hog_features = np.array(hog_features)\n",
    "# print(f\"hog_features shape: {hog_features.shape}\")\n",
    "\n",
    "# # LCP FEATURES\n",
    "# lbp_features = []\n",
    "# for i in range(10):\n",
    "#     lbp_features.append(feature_extractor.extract_lbp_features(rgb2gray(x_train[i])))\n",
    "# lbp_features = np.array(lbp_features)\n",
    "# print(f\"lbp_features shape: {lbp_features.shape}\")\n",
    "\n",
    "\n",
    "sift_features = feature_extractor.extract_sift_features(x_train[:10])\n",
    "print(f\"sift_features shape: {sift_features.shape}\")\n",
    "\n",
    "# FOURIER DESCRIPTOR FEATURES (error)\n",
    "# fourier_descriptor_features = []\n",
    "# for i in range(10):\n",
    "#     fourier_descriptor_features.append(feature_extractor.extract_fourier_descriptor_features(X_train[i]))\n",
    "# fourier_descriptor_features = np.array(fourier_descriptor_features)\n",
    "# print(f\"fourier_descriptor_features shape: {fourier_descriptor_features.shape}\")\n",
    "\n",
    "# SURF FEATURES (error)\n",
    "\n",
    "# surf_features = feature_extractor.extract_surf_features(x_train[0:10])\n",
    "# print(f\"surf_features shape: {surf_features.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = FeatureSelector()\n",
    "\n",
    "# PCA FEATURES\n",
    "gray_imgs = rgb2gray(x_train)\n",
    "\n",
    "pca_features =  feature_selector.extract_pca_features(gray_imgs,load=True)\n",
    "print(f\"pca_features shape: {pca_features.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_labels is just for trial here\n",
    "true_labels = np.concatenate((np.zeros(10), np.ones(10) * 3))\n",
    "model_selection = ModelSelection(\n",
    "    hog_features[:15], true_labels[:15], hog_features[15:], true_labels[15:]\n",
    ")\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "print(pred_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_analysis = PerformanceAnalysis('KNN', pred_train, true_labels[15:])\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
